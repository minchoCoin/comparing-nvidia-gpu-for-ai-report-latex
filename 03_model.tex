\section{이번 벤치마크에 쓰이는 인공지능 모델}
\subsection{오픈소스 기반의 그림 인공지능, Stable Diffusion}
오픈소스 기반의 그림 인공지능 중 하나인 Stable Diffusion\cite{rombach2022highresolution}는 독일 뮌헨 대학교에서
개발한 것으로, 개발 비용이 60 만달러정도였다고 예상됨에도\cite{matthias2022training} 2022 년 8 월
22 일오픈소스로 공개하였다\cite{stability2022stable}. 오픈 소스로 공개하여 로컬 컴퓨터에서 실행할 수 있으며,
Stable Diffusion 을 기반으로 한 많은 서비스가 생겼다. Stable Diffusion 을 기반으로 하는
서비스는 Novel AI 등이 있다.

Stable diffusion 은 CLIP\cite{radford2021learning}, U-Net, VAE(Variational Auto Encoder) 등 3 가지 인공신경망으로
구성되어 있다. VAE 인코더는 이미지를 픽셀 공간에서 latent space(이미지를 N 가지 특성에
따라 분류한 것, 512x512 이미지의 경우 $4\times 64\times 64$ 의 latent space 를 가진다)로 압축한다. 이때
노이즈가 추가된다.

CLIP 은 OpenAI 사에서 개발한 이미지와 텍스트 모두를 처리할 수 있는 모델이며 입력된
텍스트와 이미지를 인코딩을 통해 벡터로 변환하고 이 둘을 비교하여 유사도를 측정,
따라서 이미지 인식에 많이 쓰인다. CLIP 은 자연어를 입력하면 $77\times 768$ 의 숫자 값 목록이
생성된다. 이 목록이 U-Net 에 들어가면 이 값을 기반으로 특정 step 수에 도달할 때 까지
random latent space(text-to-image 의 경우), 입력된 이미지에 약간의 noise 가 추가된 latent 
space(image-to-image 의 경우)에서 노이즈를 반복적으로 제거하고 이것을 VAE 디코더가
픽셀 공간으로 변환하여 최종 이미지를 생성한다 U-Net 에는 8 억 6 천만 개의 파라미터가
있고, CLIP 에는 1 억 2 천 3 백만 개의 파라미터가 있다.

Stable Diffusion 의 훈련 데이터는 약 50 억개의 이미지 텍스트 쌍으로, 공개적으로 사용
가능한 데이터 세트 LAION-5B 에서 가져온 것으로 알려져 있으며, Pinterest, WordPress, 
Blogspot, DeviantArt, Wikimedia Commons 등에 있는 이미지로 구성되어 있다\cite{wiki:Stable_Diffusion}.
Stable Diffusion 의 기능은 텍스트를 이미지로 생성하는 기능과 이미지 수정 기능이 있다.

텍스트를 이미지로 생성하는 기능은 텍스트를 입력하면 이미지를 출력하는 기능이고
이미지 수정 기능은, 이미지의 해상도를 올리거나, 그림의 화풍을 바꿀 수 있다. 이런 기능을
사용할 때 이미지 생성에 영향을 주는 시드 값과 추론 단계 수(step)을 조정할 수 있다. 시드
값은 random noise 에 사용되며, 따라서 같은 seed 는 같은 random noise 를 발생시키고, 이는
같은 프롬프트에 대해 같은 이미지를 생성한다. 

추론 단계수는 noise 를 제거하는 단계 수이며, 높이면 더 많은 시간이 들고 너무 낮으면
원하는 이미지가 나오지 않을 수 있다. 또한 Stable diffusion 을 오프라인에서 브라우저를
이용하여 실행할 수 있는 Stable Diffusion WebUI 의 경우 Negative prompt 를 이용해 빼고
싶은 특성을 입력할 수도 있고, Batch size 를 통해 한번에 생성할 이미지 개수를 조정할 수
있다.
\subsection{오픈 소스 기반의 거대 언어 모델, LLaMA}
오픈 소스 기반의 거대 언어 모델은 LLaMA가 있다. LLaMA는 Meta의 오픈소스 언어모델로서 기사, 시, 이야기, 여러 질문에 대한 답변, 소스코드 등을 생성할 수 있다. 현재 LLaMA-1\cite{touvron2023llama}과 LLaMA-2\cite{touvron2023llama2} 가 공개되어 있다. LLaMA-1은 파라미터가 7B, 13B, 33B, 66B개 등을 가진 모델이 있고, LLaMA-2는 7B, 13B, 70B개의 파라미터를 가진 모델이 있다. 또한 각각 4bit양자화 모드와 8bit 양자화 모드가 있는데, 이는 모델의 파라미터를 32bit 부동소수점에서 4bit/8bit 정수로 양자화하여 계산과 메모리 access 속도를 높이는 기법이다. 이 역시 로컬에서 돌릴 수 있다\cite{raghuraman2020introduction}.

LLaMA 훈련에 사용된 데이터셋은 CommonCrawl로 스크랩한 웹페이지, GitHub에 저장되어 있는 소스코드, 20개 언어의 Wikipedia, Project Gutenberg에 업로드된 책, Stack Exchange에 올라와 있는 질문과 답변, ArXiv에 있는 논문의 LaTeX 코드 등이다.
